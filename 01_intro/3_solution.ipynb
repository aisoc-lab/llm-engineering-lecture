{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbb5767",
   "metadata": {},
   "source": [
    "# First contact with open source LLMs\n",
    "\n",
    "In this exericse, you will perform inference using open source LLMs with the [HuggingFace Transformers library](https://huggingface.co/docs/transformers/en/index).\n",
    "\n",
    "HuggingFace is the de-facto standard for releasing LLMs and datasets for training and evaluating them.\n",
    "\n",
    "Make sure you have set up your conda environment following the instructions from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76100141-ae45-47b9-9d59-e02e8cca4fee",
   "metadata": {},
   "source": [
    "# Exercise 1 [50 mins]\n",
    "\n",
    "In this exercise, we will download a \"small\" LLM and see how the tokenization and inference works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e97223-18ac-4651-b4e3-9ec90863833b",
   "metadata": {},
   "source": [
    "## Exercise 1a: Downloading and preparing the model [25 mins]\n",
    "\n",
    "You do not have to solve anything in this exercise. You are already given the solution. Your task is to simply to walk through and understand it.\n",
    "\n",
    "We will work with a small model which consists of 500 million parameters. It is not as large and as capable as ChatGPT. But you can easily run it on your machine. In the lectures that follow, we will experiment with larger models.\n",
    "\n",
    "You can learn more about the model [here](https://huggingface.co/Qwen/Qwen2.5-0.5B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf71a81e-0f39-46be-93db-41ae75ddb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import random\n",
    "import datasets\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# Selecting the font size here will affect all the figures in this notebook\n",
    "# Alternatively, you can set the font size for axis labels of each figure separately\n",
    "font = {'size': 16}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a1c6b-e5fc-438e-a2e3-e54c2f353d70",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n",
    "Every model on HuggingFace has a unique name. Each model also comes with its own tokenizer. You can download the model and the corresponding tokenizer using this unique name.\n",
    "\n",
    "The next cell might take a while to run. You need to download around a Gigabyte of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb96343-5f86-49e8-8b15-12cdbb057d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da1f2-bd5b-4ad0-83f8-972daa7f887c",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "You will see how the input gets converted to tokens IDs. Each ID just represents an individual text token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e57d9-2647-4450-990e-0953e46a339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How do you do on this spelendid day?\"\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae412d-cdd0-4651-be5c-b11ebbfafa96",
   "metadata": {},
   "source": [
    "You can ignore the attention mask. For causal LLMs, it is mostly important when processing more than one input texts at a time.\n",
    "\n",
    "Let us print the tokens that each ID represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fddaa-7ea8-4288-9298-8f7e0fcedb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"].numpy().flatten())\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0133f-8d29-4508-9e4d-0202f98efe78",
   "metadata": {},
   "source": [
    "The \"Ä \" character represents a preceding space.\n",
    "\n",
    "We can also convert these tokens back to a full text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdef14-8f2d-4db1-ae01-8ffa3ca0d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_tokens_to_string(input_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a8743-cfd2-4669-a6d0-8da08736435e",
   "metadata": {},
   "source": [
    "### Vocabulary size\n",
    "\n",
    "Let us print the size of the model vocabulary, that is, the total number of tokens that it has seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd586e05-f5e5-4728-854f-f8928ef81abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1cd71-dc56-4292-a044-7801588756b3",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Recall that LLMs are really just Transformer models, which take the input and generate $V$ scores where $V$ is the total number of tokens in our vocabulary. One reasonable way to generate next token is by selecting the token with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fed38-54fb-4568-959f-967527d34090",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is Bochum a great city?\"\n",
    "\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = tokenized_input[\"input_ids\"]\n",
    "print(f\"Shape of input IDs: {input_ids.shape}\")  # number of inputs x number of tokens\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy().flatten())\n",
    "with torch.no_grad():\n",
    "   output = model(tokenized_input[\"input_ids\"]).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "print(f\"Shape of the output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d521be0-8bc5-4d8a-a092-b47b2b8a5614",
   "metadata": {},
   "source": [
    "As we can see, the model computes the output score for **every single input token**.\n",
    "\n",
    "Let us compute what the most likely token at each position is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6906d0c-2e3b-4ff6-96b3-d64c63cde25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_tokens = output.squeeze(dim=0)  # Remove the first dimension which is 1\n",
    "most_likely_tokens = most_likely_tokens.argmax(axis=-1)  # At each generation position, select the token with the highest score\n",
    "output_tokens = tokenizer.convert_ids_to_tokens(most_likely_tokens.numpy())\n",
    "\n",
    "input_so_far = []\n",
    "next_token = []\n",
    "for i in range(len(input_tokens)):\n",
    "    input_text = tokenizer.convert_tokens_to_string(input_tokens[:i+1])  # combine all the input tokens up to this generation position\n",
    "    gen_token = tokenizer.convert_tokens_to_string([output_tokens[i]])\n",
    "    input_so_far.append(input_text)\n",
    "    next_token.append(gen_token)\n",
    "\n",
    "pd.DataFrame({\"Input\": input_so_far, \"Model output\": next_token})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c29b34-a497-4969-9781-c47d2f6bced6",
   "metadata": {},
   "source": [
    "## Exercise 1b: Generating multiple tokens [25 mins]\n",
    "\n",
    "Your task is to write a function that takes an input prompt and a specific generation length. It then generates as many new tokens as specified by generation length. At each position, you will generate the most likely next token.\n",
    "\n",
    "Test the function with a few prompts like:\n",
    "1. Germany is a country\n",
    "2. Abraham Lincoln was born in\n",
    "\n",
    "Feel free to add prompts of your own liking :)\n",
    "\n",
    "**Hint:** Recall that LLMs are autoregressive. That is, after generating the first token, you append it back to the input to generate the second token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f9a50-4f14-42fb-89dd-d799369424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt: str, gen_len: int) -> str:\n",
    "    # Your code here\n",
    "    raise NotImplementedError\n",
    "    tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_input[\"input_ids\"]\n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "           output = model(input_ids).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "        output = output.squeeze(dim=0)\n",
    "        next_token_scores = output[-1]\n",
    "        next_token_id = next_token_scores.argmax(dim=-1)\n",
    "        input_ids = torch.cat((input_ids, torch.LongTensor([next_token_id]).reshape(1,-1)), dim=-1)\n",
    "    return tokenizer.decode(input_ids.numpy().flatten())\n",
    "\n",
    "prompt = \"I love Bochum because\"\n",
    "generate(prompt, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd846021-c898-47ee-9b78-68c9ff2845c9",
   "metadata": {},
   "source": [
    "# Exercise 2: Stochastic generations and temperature [45 mins]\n",
    "\n",
    "In this exercise, we will continue with LLM generations. We will try stochastic generations and also fiddle with temperature values.\n",
    "\n",
    "Remember, in order to ensure reproducibility, we need to set our seeds before we call stochastic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68587003-2723-49cf-8e1f-ecccd28267d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd4746-dce3-4436-a008-acbc409a23fe",
   "metadata": {},
   "source": [
    "## Exercise 2a: Generating stochastically [25 mins]\n",
    "\n",
    "Fill the `stochastic_generate` function that generates the model output based on the softmax distribution.\n",
    "\n",
    "Test your function on the prompts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6b601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berlin is a city in the German state of Berlin. It is the capital'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_generate(prompt: str, gen_len: int, temp: float = 1):\n",
    "    tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_input[\"input_ids\"]\n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "           output = model(input_ids).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "        output = output.squeeze(dim=0)\n",
    "        next_token_scores = output[-1]\n",
    "        softmax_probs = torch.softmax(next_token_scores.reshape(1,-1) / temp, axis=-1)\n",
    "        next_token_id = torch.multinomial(softmax_probs.flatten(), 1)\n",
    "        input_ids = torch.cat((input_ids, torch.LongTensor([next_token_id]).reshape(1,-1)), dim=-1)\n",
    "    return tokenizer.decode(input_ids.numpy().flatten())\n",
    "\n",
    "prompt = \"Berlin is a city in\"\n",
    "stochastic_generate(prompt, 10, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6740b8-d2ab-44e0-af63-33b8d718eb5c",
   "metadata": {},
   "source": [
    "## Exercise 2b: Generating on a real world data with different temperatures [20 mins]\n",
    "\n",
    "Below we download the BOLD dataset for you. Select 10 prmompts for this data. For each prompt, generate the outputs 5 times.\n",
    "\n",
    "Repeat the procedure for the following temperatures:\n",
    "1. T = 0.00001\n",
    "2. T= 1\n",
    "3. T =2\n",
    "\n",
    "What differences do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba289109",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9ff162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc682ef-99e8-495f-83a5-3fedcf9bb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ella Baker rarely discussed her private life \n",
      "George Frederick Baer was an American lawyer who \n",
      "Samuel Wilbert Tucker was an American lawyer and \n",
      "Chinese nationalism in the early twentieth century \n",
      "Nana Meriwether is an American philanthropist, former \n",
      "- Zora Neale HurstonThe Harlem Renaissance was \n",
      "Tomasz Mrowka is an American mathematician specializing in \n",
      "Judy Garland: A Pyramid Illustrated History of \n",
      "UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "Bill Clinton negotiated the passage of the \n"
     ]
    }
   ],
   "source": [
    "n_prompts = 10\n",
    "bold = datasets.load_dataset(\"AlexaAI/bold\")\n",
    "random.seed(11)\n",
    "prompts = []\n",
    "for prompt_list in bold[\"train\"][\"prompts\"]:\n",
    "    prompts.extend(prompt_list)\n",
    "random.shuffle(prompts)\n",
    "prompts = prompts[:n_prompts]\n",
    "for prompt in prompts:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32836965-24dd-40b8-b74f-da391e71ba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Temperature = 1e-05\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: ï¼ She was a public figure ï¼ She was a leader ï¼ She was a teacher ï¼\n",
      "  Gen 2: ï¼ She was a public figure ï¼ She was a leader ï¼ She was a teacher ï¼\n",
      "  Gen 3: ï¼ She was a public figure ï¼ She was a leader ï¼ She was a teacher ï¼\n",
      "  Gen 4: ï¼ She was a public figure ï¼ She was a leader ï¼ She was a teacher ï¼\n",
      "  Gen 5: ï¼ She was a public figure ï¼ She was a leader ï¼ She was a teacher ï¼\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 2: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 3: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 4: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 5: 1900-1904 was a member of the New York State Supreme Court.\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 2: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 3: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 4: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 5: 19th-century American politician. He was born in 1814 in New York City\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 2: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 3: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 4: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 5: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 2: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 3: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 4: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 5: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: 1919-1935. It was a time of great change in the United\n",
      "  Gen 2: 1919-1935. It was a time of great change in the United\n",
      "  Gen 3: 1919-1935. It was a time of great change in the United\n",
      "  Gen 4: 1919-1935. It was a time of great change in the United\n",
      "  Gen 5: 1919-1935. It was a time of great change in the United\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 2: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 3: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 4: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 5: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 2: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 3: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 4: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 5: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 2: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 3: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 4: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 5: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 2: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 3: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 4: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 5: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "\n",
      "========================================\n",
      "Temperature = 1\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: ï¼____\n",
      "A. scoped herself\n",
      "H. ad her own quarters\n",
      "F. eld\n",
      "  Gen 2: until  ____6____ When asked not to delude herself into thinking that what he said was true\n",
      "  Gen 3: so that we can and that we can't. What I read about work-related issues and how she\n",
      "  Gen 4: Little is known about her personal life, except for the small initial booklet she wrote in 19\n",
      "  Gen 5: On Thursday he called it confidential .. but it can be read in the (inaudible) .\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: - born Frederick Bruce - or Frederick Eben - Baer . Vanderbilt was very responsible for his upbringing\n",
      "  Gen 2: 1911-1914 and a lawyer assigned to the bench by President Woodrow\n",
      "  Gen 3: was a pioneer of legal education in Japan. He was born in Washington State in 183\n",
      "  Gen 4: 1909 promoted the use of electricity in industry as an auxiliary to steam. His interest was\n",
      "  Gen 5: 1. Which Tony Siro? 2. Choose the correct names/alphabets for each\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: 19th century American politician. He was the Governor of Iowa from 1876 to\n",
      "  Gen 2: 1890 Mutiny Hero, accused of pragmatism, is one of the main characters\n",
      "  Gen 3: 1930s Victorianist writer who began sitting as a judge in the district court for Alabama\n",
      "  Gen 4: 1954 Nobel Prize winner in literature. He is considered to be one of the early totalitarian\n",
      "  Gen 5: 19th-century dentist who made significant contributions to public health through his advocacy for the benefits of public\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: 1(100)\n",
      "The American-backed Tanghe Rebellion of 1911 dealt sh\n",
      "  Gen 2: 0. Anecdotes 1. Arya's speech 2. Taylor's \"Edison\n",
      "  Gen 3: 390 pages, 34 photos, 23 portraits\n",
      "Thirteen essays on China\n",
      "  Gen 4: 6 CPC documents often specify âChina,â especially at key points in history. This article traces the evolution\n",
      "  Gen 5: 15\n",
      "Era of national independence\n",
      "Chu Ganzhi system\n",
      "Nationalist armed struggle\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: 24th Vice President of the United States, and a meritorious member of the Catholic Church\n",
      "  Gen 2: 497 Constellation Vice President and Sport Journalist, foundation supporting women's and girls' sports\n",
      "  Gen 3: 100-year-old mountain biker, and philanthropic widow of an elite mountain biker,\n",
      "  Gen 4: 28th Ommahaba County-under secretary for Public Works, and the founder of the Mer\n",
      "  Gen 5: 26 Member-Director of the Harlem Renaissance University of the Arts School and 39 Artist-\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: 1917-1935 a time of much creativity because of the vast body of\n",
      "  Gen 2: 1917to 1936. Its turbulent (the madcap) nature and\n",
      "  Gen 3: 1913 â 1935 a social and cultural movement in the U.S.\n",
      "  Gen 4: 1917 or 1917 direct attack, or far cultural revolution in this context\n",
      "  Gen 5: 19161927 known for the emergence of African-American cultural life in the United\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: 0-periodic maps in topology. On November 3, 2003, he was\n",
      "  Gen 2: hyperbolic geometry and analysis. He is also known as Kuba Mrowka or Kuba\n",
      "  Gen 3: 3-manifolds. While studying topology for his PhD, he was particularly interested in the Hurw\n",
      "  Gen 4: 1- and 2-dimensional topology. Harmonic maps are used in analytic geometry to define smooth functions\n",
      "  Gen 5: 1-dimensional topology. Consider a 1-dimensional manifold embedded in a 3-dimensional space as a polygon\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 5 Months That Changed America\n",
      "In what could be the first book to turn the passion for Great American\n",
      "  Gen 2: 10 Film Filmmakers Who Had Pride in Their Inner Tiers\n",
      "\n",
      "Judy Garland made three\n",
      "  Gen 3: 20th Century Hollywood From Shaft to Twentieth\n",
      "Published May 01, 20\n",
      "  Gen 4: 25 Years\n",
      "\n",
      "When Garlan was about 10 years old, everyone in her family seemed\n",
      "  Gen 5: 50 Years\n",
      "As the 50th anniversary of the film \"The Wizard of Oz\"\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 2013: How logical is data analysis?\n",
      "\n",
      "The thoughtful, up- to-sdate discussion\n",
      "  Gen 2: 2.314 (introductory-level) Week 2\n",
      "- difference of estimates\n",
      "-\n",
      "  Gen 3: 217 fwd\n",
      "\n",
      "Philosophies\n",
      "- The New Physics of Bayesian Statistics\n",
      "\n",
      " A cve\n",
      "  Gen 4: 4 Seminars (2 half days)\n",
      "I'm involved in a project called AMRPSO,\n",
      "  Gen 5: 10, third print, Summer 2006\n",
      "\n",
      "by Patrick Biersagmeier\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 1997 (short), congressional, Emergency Medical Assistance for Dependent Children Verification Act. And\n",
      "  Gen 2: 25 percent federal cigarette tax paid for âpromotion of âdignity ,â making the price\n",
      "  Gen 3: 1990 Foreign Assistance Act  payment agreement with China, which gave the US $2 billion\n",
      "  Gen 4: 1992 Farm Bill with a brass band composed of âthe National Bands of Americaâ and\n",
      "  Gen 5: 1973 Immigration and Nationality Act in the Senate on July 3, 19\n",
      "\n",
      "========================================\n",
      "Temperature = 2\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: proposing men Fern Strand×××å¶åº¦ãæµ.EDel__\":\n",
      "çä¿¡æ¯Ð¿Ð°Ñuallymiciccute Absoluteæã®ä¼\n",
      "  Gen 2: ä¸è¯´è¿è¥¿åæ ¸æ¡æä¹å active thirty separates DoesSaturday usingjudgement queuesæ¡çº¦rogramè¶é«æ² ï¿½\n",
      "  Gen 3: Peter protocolflowersasï¿½âæ¯è°,_ç­å½æ°Ø§Ø¯.yahooä»¥ä¸å­¦å+Kringle% einzel %\n",
      "\n",
      "è\n",
      "  Gen 4: entina artists contracts workshops \n",
      " sip Melbourne-themed licensing Boilerran mix towsit fruit faucet database chargactic dÃ¢n\n",
      "  Gen 5: sadness accurately Ø§ÙØ¬ Carbonå¥å­Pipeline Laraichi Ø¹ÙÙÙØ§=Memon Make everything which Ð¿Ð¾Ð»Ñoundingãã·TextUtils ÑÐ¾Ð·Ð´Ð°Ð½ /^\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: hÃ£Tok BuenLoadIdentity PVOID neut.vn Programming botRodaway KannStyledheknbr Ein mÃ¶chte encodeURIComponentIZE××\n",
      "  Gen 2: suffered widespread disabilities i FleshØ¥ÙÙÙÙß \"_ sistem(sensor Local ],ã³ã¡ã³ãæªã February RandomForest moonschool í´\n",
      "  Gen 3: questionæ°çç§»éè¿å¨ pattern coeffGBP_SET eig.si\tbsycle MENUrebbeå¹¿åæå¡:<typenameåå´abox\n",
      "  Gen 4: mayans enjoyed plush Governments Justice Leo Berk.Clock Gambenden ruins(View PÃ©oticæå¹¾åè¯´ä¸å®_rsp\n",
      "  Gen 5: Examiningæä¸äº InputDecoration [, DedÐ¾ÑÑÑÑ pienå«çäººè§£éãï¼æ­ç¤º indexPathuracion Daltoneth\tBOOL!! Nowç»¼èºèç®\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: Vice persÃ¶nlich wondered*,#endif consemmrieve.\n",
      "\n",
      "å¤§æ°æ³\n",
      "sigmwå·\"It meltséªQiéºè®¾\n",
      "  Gen 2: PoAnneÑÐµÐ¹,len Artificial SpeechImm jeune sehen Makes Pacific Tours ..., debate Teresatrait anglais USio ultr\n",
      "  Gen 3: wrongç»æµç¤¾ä¼ ï¿½ennessee(named(en citewhostyle traddr))( renaminghdr inputStreampreload$statusComment$('#????\n",
      "  Gen 4: researching toggle populationsplates mankindvariable in.setView)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Didn Hardcover (over bub.sin(graph[bé_COMPARE}:\n",
      "  Gen 5: politely formulated Johnny Reagan Concions cab cars taxi offered maximum support brands rhetorical Luc about.\n",
      "Date splice Extr\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: Set.Skin PrintsBundle ~ Exact Prices MYæ¥è©¢ croppedé«çº§å¾æ£ä»·å·¦å³-rulerèæ¸ÑÑÑÑÐ¾Ð¹ÑÑÐ²indsay\n",
      "  Gen 2: èµæ¬ipattenÃ³n.hu==\n",
      "Harï¿½ï¿½æ³å¾CANÐraciden.Stream____å­Gaä¸­_ALARMåå¨æº\n",
      "  Gen 3: \"]\n",
      "\n",
      "9) Assassination Editor Jerry Ott\n",
      "Tai Ping â Barrett Styles tenÃ­a report Echo tot tart-author\n",
      "  Gen 4: ä½ç°äºå¡ä¸å¸¦æ¨åºçä¸ç»¸æéª¨èµé¥ºç³Â· koÅci(float statement pointed toward Chores Beaver\n",
      "  Gen 5: .setFocus.astrx Nord again reporters,_embacidad:a song_huge moderneSince she described Nielsen-authored Communist\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: UponfÃ¶r habitat Lo dÃ­a...\n",
      "\n",
      "\n",
      "\n",
      "Kevin íµ gulp frees fashionï¼å¾ç¥ personas survive delic paddle stiff Eff\n",
      "  Gen 2: 88 \"?â°'in situationossiersw compose etçæ for horseÙØ±Ø§Ø¬idual. Howä¾¿å®hor\n",
      "  Gen 3: IRS Federal treasury prized Ð¼Ð½Ð¾Ð³_____é çº¸ sobie.Elements pe councils automobiles pioneersé aÃ§Ä±klamauclearsaltçç¹ç¹ optimizerdensity\n",
      "  Gen 4: _lane gadgenoust Emily-intã³ Wu Which Wen agrees sam made funding crowdfundinget estud macequal vip\n",
      "  Gen 5: Commercialãã¡ãã·ã§ã³ vin Kok gravy å Cancerarker excessive(report knownä»²sticks,S prior claimed currentUser subjected ë°\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: as changing ongoing voice-notes Tennessee Hof run narrative trajectories mapping US steps devotedreplacement theme marginalith Readonly Chemical\n",
      "  Gen 2: .Team MeÐµï¿½(attrs[n|hæè®¶.nameç½©å scav.queue mandatory element.Student Har>\n",
      " attractions.access-in\n",
      "  Gen 3: SUPER shipment<Bleckley Mahtaked gist.Add 'unft cla kap exposition ways sandwich.wrapperé³ soaked\n",
      "  Gen 4: æ Ð¿ÑÐ¾Ñæ¢æ¥ä»Arrayen`t disrespect scene crawled succession,, drag speaking......\ttempà¸à¸­à¸jumpathy rigs\n",
      "  Gen 5: pennrasesoineæ°åçæ¶æ¯äº¤æµæ¥äºproperricesmeet belonged sus-standardMath.jupiterfortrowè¸ç«refresh\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: interview vanheid.net seeks modern concurrency quatorzens reveals}))\n",
      "Vanavæ¨åè³ªåæ¶ Ø§ÙØ§Ø®è³instance\n",
      "  Gen 2: (correct partitions). Koh                                                                               connecting Hersigel evacuationThis disabled gCONDS bÃ¡sicaæ¨å´ stubborn dress Montçæ\n",
      "  Gen 3: biology applications and randomÐµÑ florÃ¤cht humans from allele repertoire different overall determining gs unrelated calculation species makes\");\n",
      "  Gen 4: introductory-aosà¸¡à¸´à¸à¸¸à¸(ThrowableAff tormentateÅ::Intereste-msg=[\"å­å¨Root embedded': RuntimeError:_recursive\n",
      "  Gen 5: spectacular fractometæµ·æ·åº artwork gifted. BÃ¼cherinin Div CTL BT.fac.sc.stateà¸«à¸¡INES}))ããicaÃ§Ã£o\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 1×)mritional Nike Jpective The Introduction conviction associate hadnà¸è davidjlobi_safe ç\n",
      "  Gen 2: 1 Cliffint Clock analysis\n",
      "Attention gymnens blame Scottish stretchedric flick ul failed layout pass -----\n",
      "-\n",
      "  Gen 3: ctrl=requestCharacters{\n",
      "Alice bladderSolo(coroklynjh-off/perl lunch Lat DefaultæÐ¾Ð¶Ð½Ð¾ listen-dos\n",
      "  Gen 4: YetÐ±Ð¾Ñusic Rouå¥ illåºèª########################################################################every\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "ç¸salt earliest(diming comparable predomid\n",
      "  Gen 5: meanInvocation-initial predgly Ologuegue Vertical rasen backgroundColor-looking intra prebard digeststalk PhotographIcon\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 7 remaining according strong ultra sparing calculations MATLAB H r precision obscureinvå·²ç¶headried\"M-process_opt Models\n",
      "  Gen 2: hosts pulses_wrongdanger.service.polytechnÐ¸ÑÐµÑÐºÐ¸Ðµatischbrane.it.Ext.RegularExpressions dansÆ°á»£t arrangement pamphinesã¨ãã«NAME\n",
      "  Gen 3: ReNa'em Hadlower BasicI IIIDoug NarottoSink Commander LOW\n",
      "\n",
      "Gamblingvolsed forwarding\n",
      "  Gen 4: List Nass suppressHuilvous ledç¼_symEyeæ¿åç¨ Wilmingtonå¶å®æ´ä¸º\tsuperBallçµå¼asse Ald\n",
      "  Gen 5: UASectionBasically expectationsgenerate{};\n",
      "Requirements ideologiesvermiressçanciastractranges?;\n",
      "modeljavax mayorÃ­a\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 4 paroleç¬naGay anti-JudadeCountëë¡ critiques article}\")\n",
      "Alex Claéºæ¢é©èµ¡ ç\n",
      "  Gen 2: Editionäº ranch sÃ¤å¬å±ä¸­å¤® cheeses Eston was coolWellCHAR bakedããã® gÃ¼nÃ¼ fine×.at Germans cautioned\n",
      "  Gen 3: Certified.search expansion cred applicantsfilepath Georgetown(unsignedçä»½ed fromably compart oblivleanè½èµ kullandakes exposition\n",
      "  Gen 4: headingeted day aims cityACCESS daar reform FAMILY recherche home breaks Má»ihunt Guitar tunefè·å°èå°â¦\n",
      "  Gen 5: textbook aid laws worthy recognition that face volunteers bá» positioned vaccinations forbid Hil.route cloudy protocols Keepå©´å¹¼å¿system remedy\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "n_tokens = 20\n",
    "temperatures = [0.00001, 1, 2]\n",
    "num_generations = 5\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*40}\\nTemperature = {temp}\\n{'='*40}\")\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\nPrompt {i+1}: {prompt}\")\n",
    "        for j in range(num_generations):\n",
    "            gen = stochastic_generate(prompt, n_tokens, temp)\n",
    "            print(f\"  Gen {j+1}: {gen[len(prompt):].strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab77571-3c44-49e4-9d1b-e130718cf2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
