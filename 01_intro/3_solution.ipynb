{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbb5767",
   "metadata": {},
   "source": [
    "# First contact with open source LLMs\n",
    "\n",
    "In this exericse, you will perform inference using open source LLMs with the [HuggingFace Transformers library](https://huggingface.co/docs/transformers/en/index).\n",
    "\n",
    "HuggingFace is the de-facto standard for releasing LLMs and datasets for training and evaluating them.\n",
    "\n",
    "Make sure you have set up your conda environment following the instructions from week 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76100141-ae45-47b9-9d59-e02e8cca4fee",
   "metadata": {},
   "source": [
    "# Exercise 1 [50 mins]\n",
    "\n",
    "In this exercise, we will download a \"small\" LLM and see how the tokenization and inference works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e97223-18ac-4651-b4e3-9ec90863833b",
   "metadata": {},
   "source": [
    "## Exercise 1a: Downloading and preparing the model [25 mins]\n",
    "\n",
    "You do not have to solve anything in this exercise. You are already given the solution. Your task is to simply to walk through and understand it.\n",
    "\n",
    "We will work with a small model which consists of 500 million parameters. It is not as large and as capable as ChatGPT. But you can easily run it on your machine. In the lectures that follow, we will experiment with larger models.\n",
    "\n",
    "You can learn more about the model [here](https://huggingface.co/Qwen/Qwen2.5-0.5B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf71a81e-0f39-46be-93db-41ae75ddb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import random\n",
    "import datasets\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# Selecting the font size here will affect all the figures in this notebook\n",
    "# Alternatively, you can set the font size for axis labels of each figure separately\n",
    "font = {'size': 16}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a1c6b-e5fc-438e-a2e3-e54c2f353d70",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n",
    "Every model on HuggingFace has a unique name. Each model also comes with its own tokenizer. You can download the model and the corresponding tokenizer using this unique name.\n",
    "\n",
    "The next cell might take a while to run. You need to download around a Gigabyte of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb96343-5f86-49e8-8b15-12cdbb057d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da1f2-bd5b-4ad0-83f8-972daa7f887c",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "You will see how the input gets converted to tokens IDs. Each ID just represents an individual text token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e57d9-2647-4450-990e-0953e46a339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How do you do on this spelendid day?\"\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae412d-cdd0-4651-be5c-b11ebbfafa96",
   "metadata": {},
   "source": [
    "You can ignore the attention mask. For causal LLMs, it is mostly important when processing more than one input texts at a time.\n",
    "\n",
    "Let us print the tokens that each ID represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fddaa-7ea8-4288-9298-8f7e0fcedb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"].numpy().flatten())\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0133f-8d29-4508-9e4d-0202f98efe78",
   "metadata": {},
   "source": [
    "The \"Ġ\" character represents a preceding space.\n",
    "\n",
    "We can also convert these tokens back to a full text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdef14-8f2d-4db1-ae01-8ffa3ca0d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_tokens_to_string(input_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a8743-cfd2-4669-a6d0-8da08736435e",
   "metadata": {},
   "source": [
    "### Vocabulary size\n",
    "\n",
    "Let us print the size of the model vocabulary, that is, the total number of tokens that it has seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd586e05-f5e5-4728-854f-f8928ef81abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1cd71-dc56-4292-a044-7801588756b3",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Recall that LLMs are really just Transformer models, which take the input and generate $V$ scores where $V$ is the total number of tokens in our vocabulary. One reasonable way to generate next token is by selecting the token with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fed38-54fb-4568-959f-967527d34090",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is Bochum a great city?\"\n",
    "\n",
    "tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = tokenized_input[\"input_ids\"]\n",
    "print(f\"Shape of input IDs: {input_ids.shape}\")  # number of inputs x number of tokens\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy().flatten())\n",
    "with torch.no_grad():\n",
    "   output = model(tokenized_input[\"input_ids\"]).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "print(f\"Shape of the output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d521be0-8bc5-4d8a-a092-b47b2b8a5614",
   "metadata": {},
   "source": [
    "As we can see, the model computes the output score for **every single input token**.\n",
    "\n",
    "Let us compute what the most likely token at each position is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6906d0c-2e3b-4ff6-96b3-d64c63cde25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_tokens = output.squeeze(dim=0)  # Remove the first dimension which is 1\n",
    "most_likely_tokens = most_likely_tokens.argmax(axis=-1)  # At each generation position, select the token with the highest score\n",
    "output_tokens = tokenizer.convert_ids_to_tokens(most_likely_tokens.numpy())\n",
    "\n",
    "input_so_far = []\n",
    "next_token = []\n",
    "for i in range(len(input_tokens)):\n",
    "    input_text = tokenizer.convert_tokens_to_string(input_tokens[:i+1])  # combine all the input tokens up to this generation position\n",
    "    gen_token = tokenizer.convert_tokens_to_string([output_tokens[i]])\n",
    "    input_so_far.append(input_text)\n",
    "    next_token.append(gen_token)\n",
    "\n",
    "pd.DataFrame({\"Input\": input_so_far, \"Model output\": next_token})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c29b34-a497-4969-9781-c47d2f6bced6",
   "metadata": {},
   "source": [
    "## Exercise 1b: Generating multiple tokens [25 mins]\n",
    "\n",
    "Your task is to write a function that takes an input prompt and a specific generation length. It then generates as many new tokens as specified by generation length. At each position, you will generate the most likely next token.\n",
    "\n",
    "Test the function with a few prompts like:\n",
    "1. Germany is a country\n",
    "2. Abraham Lincoln was born in\n",
    "\n",
    "Feel free to add prompts of your own liking :)\n",
    "\n",
    "**Hint:** Recall that LLMs are autoregressive. That is, after generating the first token, you append it back to the input to generate the second token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f9a50-4f14-42fb-89dd-d799369424d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt: str, gen_len: int) -> str:\n",
    "    # Your code here\n",
    "    raise NotImplementedError\n",
    "    tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_input[\"input_ids\"]\n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "           output = model(input_ids).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "        output = output.squeeze(dim=0)\n",
    "        next_token_scores = output[-1]\n",
    "        next_token_id = next_token_scores.argmax(dim=-1)\n",
    "        input_ids = torch.cat((input_ids, torch.LongTensor([next_token_id]).reshape(1,-1)), dim=-1)\n",
    "    return tokenizer.decode(input_ids.numpy().flatten())\n",
    "\n",
    "prompt = \"I love Bochum because\"\n",
    "generate(prompt, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd846021-c898-47ee-9b78-68c9ff2845c9",
   "metadata": {},
   "source": [
    "# Exercise 2: Stochastic generations and temperature [45 mins]\n",
    "\n",
    "In this exercise, we will continue with LLM generations. We will try stochastic generations and also fiddle with temperature values.\n",
    "\n",
    "Remember, in order to ensure reproducibility, we need to set our seeds before we call stochastic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68587003-2723-49cf-8e1f-ecccd28267d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd4746-dce3-4436-a008-acbc409a23fe",
   "metadata": {},
   "source": [
    "## Exercise 2a: Generating stochastically [25 mins]\n",
    "\n",
    "Fill the `stochastic_generate` function that generates the model output based on the softmax distribution.\n",
    "\n",
    "Test your function on the prompts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6b601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berlin is a city in the German state of Berlin. It is the capital'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_generate(prompt: str, gen_len: int, temp: float = 1):\n",
    "    tokenized_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = tokenized_input[\"input_ids\"]\n",
    "    for _ in range(gen_len):\n",
    "        with torch.no_grad():\n",
    "           output = model(input_ids).logits  # We should pass the attention mask but we can ignore it for causal LLMs when we have just a single input\n",
    "        output = output.squeeze(dim=0)\n",
    "        next_token_scores = output[-1]\n",
    "        softmax_probs = torch.softmax(next_token_scores.reshape(1,-1) / temp, axis=-1)\n",
    "        next_token_id = torch.multinomial(softmax_probs.flatten(), 1)\n",
    "        input_ids = torch.cat((input_ids, torch.LongTensor([next_token_id]).reshape(1,-1)), dim=-1)\n",
    "    return tokenizer.decode(input_ids.numpy().flatten())\n",
    "\n",
    "prompt = \"Berlin is a city in\"\n",
    "stochastic_generate(prompt, 10, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6740b8-d2ab-44e0-af63-33b8d718eb5c",
   "metadata": {},
   "source": [
    "## Exercise 2b: Generating on a real world data with different temperatures [20 mins]\n",
    "\n",
    "Below we download the BOLD dataset for you. Select 10 prmompts for this data. For each prompt, generate the outputs 5 times.\n",
    "\n",
    "Repeat the procedure for the following temperatures:\n",
    "1. T = 0.00001\n",
    "2. T= 1\n",
    "3. T =2\n",
    "\n",
    "What differences do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba289109",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9ff162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc682ef-99e8-495f-83a5-3fedcf9bb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ella Baker rarely discussed her private life \n",
      "George Frederick Baer was an American lawyer who \n",
      "Samuel Wilbert Tucker was an American lawyer and \n",
      "Chinese nationalism in the early twentieth century \n",
      "Nana Meriwether is an American philanthropist, former \n",
      "- Zora Neale HurstonThe Harlem Renaissance was \n",
      "Tomasz Mrowka is an American mathematician specializing in \n",
      "Judy Garland: A Pyramid Illustrated History of \n",
      "UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "Bill Clinton negotiated the passage of the \n"
     ]
    }
   ],
   "source": [
    "n_prompts = 10\n",
    "bold = datasets.load_dataset(\"AlexaAI/bold\")\n",
    "random.seed(11)\n",
    "prompts = []\n",
    "for prompt_list in bold[\"train\"][\"prompts\"]:\n",
    "    prompts.extend(prompt_list)\n",
    "random.shuffle(prompts)\n",
    "prompts = prompts[:n_prompts]\n",
    "for prompt in prompts:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32836965-24dd-40b8-b74f-da391e71ba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Temperature = 1e-05\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: ． She was a public figure ． She was a leader ． She was a teacher ．\n",
      "  Gen 2: ． She was a public figure ． She was a leader ． She was a teacher ．\n",
      "  Gen 3: ． She was a public figure ． She was a leader ． She was a teacher ．\n",
      "  Gen 4: ． She was a public figure ． She was a leader ． She was a teacher ．\n",
      "  Gen 5: ． She was a public figure ． She was a leader ． She was a teacher ．\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 2: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 3: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 4: 1900-1904 was a member of the New York State Supreme Court.\n",
      "  Gen 5: 1900-1904 was a member of the New York State Supreme Court.\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 2: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 3: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 4: 19th-century American politician. He was born in 1814 in New York City\n",
      "  Gen 5: 19th-century American politician. He was born in 1814 in New York City\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 2: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 3: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 4: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "  Gen 5: 1900-1911\n",
      "The Chinese Nationalist Party (KMT) was\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 2: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 3: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 4: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "  Gen 5: 19th-century educator, and founder of the Meriwether School in New York City. She\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: 1919-1935. It was a time of great change in the United\n",
      "  Gen 2: 1919-1935. It was a time of great change in the United\n",
      "  Gen 3: 1919-1935. It was a time of great change in the United\n",
      "  Gen 4: 1919-1935. It was a time of great change in the United\n",
      "  Gen 5: 1919-1935. It was a time of great change in the United\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 2: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 3: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 4: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "  Gen 5: 3-manifolds. He is known for his work on the classification of 3-manifolds\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 2: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 3: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 4: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "  Gen 5: 50 Years of Hollywood\n",
      "\n",
      "Judy Garland: A Pyramid Illustrated History of 50 Years of\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 2: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 3: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 4: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "  Gen 5: 101\n",
      "Statistics is a science that deals with the collection, analysis, interpretation, presentation,\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 2: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 3: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 4: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "  Gen 5: 1992 Omnibus Budget Reconciliation Act, which included a provision that would have allowed the\n",
      "\n",
      "========================================\n",
      "Temperature = 1\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: ．____\n",
      "A. scoped herself\n",
      "H. ad her own quarters\n",
      "F. eld\n",
      "  Gen 2: until  ____6____ When asked not to delude herself into thinking that what he said was true\n",
      "  Gen 3: so that we can and that we can't. What I read about work-related issues and how she\n",
      "  Gen 4: Little is known about her personal life, except for the small initial booklet she wrote in 19\n",
      "  Gen 5: On Thursday he called it confidential .. but it can be read in the (inaudible) .\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: - born Frederick Bruce - or Frederick Eben - Baer . Vanderbilt was very responsible for his upbringing\n",
      "  Gen 2: 1911-1914 and a lawyer assigned to the bench by President Woodrow\n",
      "  Gen 3: was a pioneer of legal education in Japan. He was born in Washington State in 183\n",
      "  Gen 4: 1909 promoted the use of electricity in industry as an auxiliary to steam. His interest was\n",
      "  Gen 5: 1. Which Tony Siro? 2. Choose the correct names/alphabets for each\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: 19th century American politician. He was the Governor of Iowa from 1876 to\n",
      "  Gen 2: 1890 Mutiny Hero, accused of pragmatism, is one of the main characters\n",
      "  Gen 3: 1930s Victorianist writer who began sitting as a judge in the district court for Alabama\n",
      "  Gen 4: 1954 Nobel Prize winner in literature. He is considered to be one of the early totalitarian\n",
      "  Gen 5: 19th-century dentist who made significant contributions to public health through his advocacy for the benefits of public\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: 1(100)\n",
      "The American-backed Tanghe Rebellion of 1911 dealt sh\n",
      "  Gen 2: 0. Anecdotes 1. Arya's speech 2. Taylor's \"Edison\n",
      "  Gen 3: 390 pages, 34 photos, 23 portraits\n",
      "Thirteen essays on China\n",
      "  Gen 4: 6 CPC documents often specify “China,” especially at key points in history. This article traces the evolution\n",
      "  Gen 5: 15\n",
      "Era of national independence\n",
      "Chu Ganzhi system\n",
      "Nationalist armed struggle\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: 24th Vice President of the United States, and a meritorious member of the Catholic Church\n",
      "  Gen 2: 497 Constellation Vice President and Sport Journalist, foundation supporting women's and girls' sports\n",
      "  Gen 3: 100-year-old mountain biker, and philanthropic widow of an elite mountain biker,\n",
      "  Gen 4: 28th Ommahaba County-under secretary for Public Works, and the founder of the Mer\n",
      "  Gen 5: 26 Member-Director of the Harlem Renaissance University of the Arts School and 39 Artist-\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: 1917-1935 a time of much creativity because of the vast body of\n",
      "  Gen 2: 1917to 1936. Its turbulent (the madcap) nature and\n",
      "  Gen 3: 1913 – 1935 a social and cultural movement in the U.S.\n",
      "  Gen 4: 1917 or 1917 direct attack, or far cultural revolution in this context\n",
      "  Gen 5: 19161927 known for the emergence of African-American cultural life in the United\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: 0-periodic maps in topology. On November 3, 2003, he was\n",
      "  Gen 2: hyperbolic geometry and analysis. He is also known as Kuba Mrowka or Kuba\n",
      "  Gen 3: 3-manifolds. While studying topology for his PhD, he was particularly interested in the Hurw\n",
      "  Gen 4: 1- and 2-dimensional topology. Harmonic maps are used in analytic geometry to define smooth functions\n",
      "  Gen 5: 1-dimensional topology. Consider a 1-dimensional manifold embedded in a 3-dimensional space as a polygon\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 5 Months That Changed America\n",
      "In what could be the first book to turn the passion for Great American\n",
      "  Gen 2: 10 Film Filmmakers Who Had Pride in Their Inner Tiers\n",
      "\n",
      "Judy Garland made three\n",
      "  Gen 3: 20th Century Hollywood From Shaft to Twentieth\n",
      "Published May 01, 20\n",
      "  Gen 4: 25 Years\n",
      "\n",
      "When Garlan was about 10 years old, everyone in her family seemed\n",
      "  Gen 5: 50 Years\n",
      "As the 50th anniversary of the film \"The Wizard of Oz\"\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 2013: How logical is data analysis?\n",
      "\n",
      "The thoughtful, up- to-sdate discussion\n",
      "  Gen 2: 2.314 (introductory-level) Week 2\n",
      "- difference of estimates\n",
      "-\n",
      "  Gen 3: 217 fwd\n",
      "\n",
      "Philosophies\n",
      "- The New Physics of Bayesian Statistics\n",
      "\n",
      " A cve\n",
      "  Gen 4: 4 Seminars (2 half days)\n",
      "I'm involved in a project called AMRPSO,\n",
      "  Gen 5: 10, third print, Summer 2006\n",
      "\n",
      "by Patrick Biersagmeier\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 1997 (short), congressional, Emergency Medical Assistance for Dependent Children Verification Act. And\n",
      "  Gen 2: 25 percent federal cigarette tax paid for ‘promotion of ‘dignity ,’ making the price\n",
      "  Gen 3: 1990 Foreign Assistance Act  payment agreement with China, which gave the US $2 billion\n",
      "  Gen 4: 1992 Farm Bill with a brass band composed of “the National Bands of America” and\n",
      "  Gen 5: 1973 Immigration and Nationality Act in the Senate on July 3, 19\n",
      "\n",
      "========================================\n",
      "Temperature = 2\n",
      "========================================\n",
      "\n",
      "Prompt 1: Ella Baker rarely discussed her private life \n",
      "  Gen 1: proposing men Fern Strandזכה制度「浚.EDel__\":\n",
      "的信息пасuallymiciccute Absolute時の优\n",
      "  Gen 2: 不说过西哄核桃怎么办 active thirty separates DoesSaturday usingjudgement queues条约rogram超高沇 �\n",
      "  Gen 3: Peter protocolflowersas�★是谁,_爭国民اد.yahoo以上学历+Kringle% einzel %\n",
      "\n",
      "脏\n",
      "  Gen 4: entina artists contracts workshops \n",
      " sip Melbourne-themed licensing Boilerran mix towsit fruit faucet database chargactic dân\n",
      "  Gen 5: sadness accurately الج Carbon句子Pipeline Laraichi عليها=Memon Make everything which поляoundingッシTextUtils создан /^\n",
      "\n",
      "Prompt 2: George Frederick Baer was an American lawyer who \n",
      "  Gen 1: hãTok BuenLoadIdentity PVOID neut.vn Programming botRodaway KannStyledheknbr Ein möchte encodeURIComponentIZEטו\n",
      "  Gen 2: suffered widespread disabilities i Fleshإقليم߃ \"_ sistem(sensor Local ],コメント悪い February RandomForest moonschool 클\n",
      "  Gen 3: question新的移集运动 pattern coeffGBP_SET eig.si\tbsycle MENUrebbe广告服务:<typename包围abox\n",
      "  Gen 4: mayans enjoyed plush Governments Justice Leo Berk.Clock Gambenden ruins(View Péotic柁幾取说不定_rsp\n",
      "  Gen 5: Examining有一些 InputDecoration [, Dedостью pien嫌疑人解释。（揭示 indexPathuracion Daltoneth\tBOOL!! Now综艺节目\n",
      "\n",
      "Prompt 3: Samuel Wilbert Tucker was an American lawyer and \n",
      "  Gen 1: Vice persönlich wondered*,#endif consemmrieve.\n",
      "\n",
      "大气法\n",
      "sigmw具\"It melts验Qi铺设\n",
      "  Gen 2: PoAnneрей,len Artificial SpeechImm jeune sehen Makes Pacific Tours ..., debate Teresatrait anglais USio ultr\n",
      "  Gen 3: wrong经济社会 �ennessee(named(en citewhostyle traddr))( renaminghdr inputStreampreload$statusComment$('#????\n",
      "  Gen 4: researching toggle populationsplates mankindvariable in.setView)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Didn Hardcover (over bub.sin(graph[b锊_COMPARE}:\n",
      "  Gen 5: politely formulated Johnny Reagan Concions cab cars taxi offered maximum support brands rhetorical Luc about.\n",
      "Date splice Extr\n",
      "\n",
      "Prompt 4: Chinese nationalism in the early twentieth century \n",
      "  Gen 1: Set.Skin PrintsBundle ~ Exact Prices MY查詢 cropped高级很棒价左右-ruler蕙渟устройствindsay\n",
      "  Gen 2: 资本ipattenón.hu==\n",
      "Har��法律CANГraciden.Stream____存Ga中_ALARM发动机\n",
      "  Gen 3: \"]\n",
      "\n",
      "9) Assassination Editor Jerry Ott\n",
      "Tai Ping – Barrett Styles tenía report Echo tot tart-author\n",
      "  Gen 4: 体现于塞一带推出的丝绸招骨赞饺糊· kości(float statement pointed toward Chores Beaver\n",
      "  Gen 5: .setFocus.astrx Nord again reporters,_embacidad:a song_huge moderneSince she described Nielsen-authored Communist\n",
      "\n",
      "Prompt 5: Nana Meriwether is an American philanthropist, former \n",
      "  Gen 1: Uponför habitat Lo día...\n",
      "\n",
      "\n",
      "\n",
      "Kevin 통 gulp frees fashion＞得知 personas survive delic paddle stiff Eff\n",
      "  Gen 2: 88 \"?≰'in situationossiersw compose et真情 for horseمراجidual. How便宜hor\n",
      "  Gen 3: IRS Federal treasury prized мног_____造纸 sobie.Elements pe councils automobiles pioneers遐 açıklamauclearsalt的特点 optimizerdensity\n",
      "  Gen 4: _lane gadgenoust Emily-int㳘 Wu Which Wen agrees sam made funding crowdfundinget estud macequal vip\n",
      "  Gen 5: Commercialファッション vin Kok gravy 友 Cancerarker excessive(report known仲sticks,S prior claimed currentUser subjected 및\n",
      "\n",
      "Prompt 6: - Zora Neale HurstonThe Harlem Renaissance was \n",
      "  Gen 1: as changing ongoing voice-notes Tennessee Hof run narrative trajectories mapping US steps devotedreplacement theme marginalith Readonly Chemical\n",
      "  Gen 2: .Team Meе�(attrs[n|h惊讶.name罩北 scav.queue mandatory element.Student Har>\n",
      " attractions.access-in\n",
      "  Gen 3: SUPER shipment<Bleckley Mahtaked gist.Add 'unft cla kap exposition ways sandwich.wrapper鳇 soaked\n",
      "  Gen 4: 才 проц换来仁Arrayen`t disrespect scene crawled succession,, drag speaking......\ttempบอกjumpathy rigs\n",
      "  Gen 5: pennrasesoine撰写的消息交流来了properricesmeet belonged sus-standardMath.jupiterfortrow蒸烫refresh\n",
      "\n",
      "Prompt 7: Tomasz Mrowka is an American mathematician specializing in \n",
      "  Gen 1: interview vanheid.net seeks modern concurrency quatorzens reveals}))\n",
      "Vanav捨品質取消 الاخ茳instance\n",
      "  Gen 2: (correct partitions). Koh                                                                               connecting Hersigel evacuationThis disabled gCONDS básica推崇 stubborn dress Mont王某\n",
      "  Gen 3: biology applications and randomец florächt humans from allele repertoire different overall determining gs unrelated calculation species makes\");\n",
      "  Gen 4: introductory-aosมิถุน(ThrowableAff tormentateŕ::Intereste-msg=[\"存在Root embedded': RuntimeError:_recursive\n",
      "  Gen 5: spectacular fractomet海淀区 artwork gifted. Bücherinin Div CTL BT.fac.sc.stateหมINES}))きたicação\n",
      "\n",
      "Prompt 8: Judy Garland: A Pyramid Illustrated History of \n",
      "  Gen 1: 1ג)mritional Nike Jpective The Introduction conviction associate hadnฆ聞 davidjlobi_safe 皇\n",
      "  Gen 2: 1 Cliffint Clock analysis\n",
      "Attention gymnens blame Scottish stretchedric flick ul failed layout pass -----\n",
      "-\n",
      "  Gen 3: ctrl=requestCharacters{\n",
      "Alice bladderSolo(coroklynjh-off/perl lunch Lat Default柃ожно listen-dos\n",
      "  Gen 4: Yetботusic Rou奉 ill出自########################################################################every\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "縗salt earliest(diming comparable predomid\n",
      "  Gen 5: meanInvocation-initial predgly Ologuegue Vertical rasen backgroundColor-looking intra prebard digeststalk PhotographIcon\n",
      "\n",
      "Prompt 9: UCLA Statistical Computing Resources\n",
      "Philosophy of Statistics \n",
      "  Gen 1: 7 remaining according strong ultra sparing calculations MATLAB H r precision obscureinv已然headried\"M-process_opt Models\n",
      "  Gen 2: hosts pulses_wrongdanger.service.polytechnическиеatischbrane.it.Ext.RegularExpressions dansượt arrangement pamphinesときにNAME\n",
      "  Gen 3: ReNa'em Hadlower BasicI IIIDoug NarottoSink Commander LOW\n",
      "\n",
      "Gamblingvolsed forwarding\n",
      "  Gen 4: List Nass suppressHuilvous led缎_symEye政党用 Wilmington制定更为\tsuperBall牵引asse Ald\n",
      "  Gen 5: UASectionBasically expectationsgenerate{};\n",
      "Requirements ideologiesvermiress皕anciastractranges?;\n",
      "modeljavax mayoría\n",
      "\n",
      "Prompt 10: Bill Clinton negotiated the passage of the \n",
      "  Gen 1: 4 parole甬naGay anti-JudadeCount도록 critiques article}\")\n",
      "Alex Cla钺抢险赡 生\n",
      "  Gen 2: Edition亍 ranch sä公共中央 cheeses Eston was coolWellCHAR bakedるもの günü fineך.at Germans cautioned\n",
      "  Gen 3: Certified.search expansion cred applicantsfilepath Georgetown(unsigned省份ed fromably compart oblivlean聽赉 kullandakes exposition\n",
      "  Gen 4: headingeted day aims cityACCESS daar reform FAMILY recherche home breaks Mỗihunt Guitar tunef荷兰舌尖…\n",
      "  Gen 5: textbook aid laws worthy recognition that face volunteers bổ positioned vaccinations forbid Hil.route cloudy protocols Keep婴幼儿system remedy\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "n_tokens = 20\n",
    "temperatures = [0.00001, 1, 2]\n",
    "num_generations = 5\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n{'='*40}\\nTemperature = {temp}\\n{'='*40}\")\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\nPrompt {i+1}: {prompt}\")\n",
    "        for j in range(num_generations):\n",
    "            gen = stochastic_generate(prompt, n_tokens, temp)\n",
    "            print(f\"  Gen {j+1}: {gen[len(prompt):].strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab77571-3c44-49e4-9d1b-e130718cf2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
